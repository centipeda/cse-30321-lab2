{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "dogs_cats_birds_caseXX.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S1JOLforVjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using tf.2.1 in colab\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# sanity check for the tf version\n",
        "print(tf.__version__)\n",
        "\n",
        "###################################################################################################\n",
        "# Define image size for network model -- all input images are scaled to this size.\n",
        "###################################################################################################   \n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "###################################################################################################\n",
        "# Include pointers to training and validation data folders -- be sure to examine subfolder structure\n",
        "# --> I also define the # of training samples, validation samples, epochs, and batch size here.\n",
        "###################################################################################################   \n",
        "train_data_dir = '/content/gdrive/My Drive/cse-30321-lab2/Datasets/data/train'\n",
        "validation_data_dir = '/content/gdrive/My Drive/cse-30321-lab2/Datasets/data/validation'\n",
        "nb_train_samples = 5000\n",
        "nb_validation_samples = 1000\n",
        "epochs = 30\n",
        "batch_size = 100\n",
        "\n",
        "###################################################################################################\n",
        "# As before, this code simply organizes input data such that channels either come first or last\n",
        "# depending on the backend used (TensorFlow or Theano)\n",
        "###################################################################################################   \n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "###################################################################################################\n",
        "# Define our CNN model\n",
        "###################################################################################################\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "################################################\n",
        "# INSERT YOUR CODE HERE\n",
        "################################################\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "###################################################################################################\n",
        "# To process images in respective directories, we can use the ImageDataGenerator class\n",
        "#\tThe code provided here normalizes image data, etc.\n",
        "#\tThe parameters will not be discussed further here, \n",
        "#    but more information / options can be found at:  https://keras.io/preprocessing/image/ \n",
        "###################################################################################################   \n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "###################################################################################################\n",
        "# This is the augmentation configuration we will use for testing:  only rescaling\n",
        "###################################################################################################\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "###################################################################################################\n",
        "# Subsequent invocations of flow_from_directory() will use the paths to the training and validation \n",
        "# data, and generate batches of data\n",
        "# \n",
        "# Note that if you wanted to work with grayscale images (for example) you could simply change \n",
        "# color_mode to ‘gray_scale’ (and the number of color channels)\n",
        "# \n",
        "# Again, you will not need to change any parameters here, but a more detailed description of this \n",
        "# class can also be found at the link above.\n",
        "###################################################################################################\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "###################################################################################################\n",
        "# Finally, the invocation of model.fit_generator will simply train the model on batches of data.  \n",
        "# More information can be found at:  https://keras.io/models/sequential/\n",
        "# --> However, this is just analogous to model.fit() discussed in other examples.\n",
        "###################################################################################################\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch= nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "import pandas as pd\n",
        "hist_df = pd.DataFrame(history.history) \n",
        "hist_csv_file = '/content/gdrive/My Drive/cse-30321-lab2/dogs_cats_birds_model_case01_30epoch.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "###################################################################################################\n",
        "# Here, we save the model weights and generate an image of the network...\n",
        "###################################################################################################\n",
        "model.save('/content/gdrive/My Drive/cse-30321-lab2/dogs_cats_birds_model_caseXX_30epoch')\n",
        "\n",
        "plot_model(model, to_file='/content/gdrive/My Drive/cse-30321-lab2/dogs_cats_birds_model_caseXX.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsfBizwSk8Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}